# .github/workflows/find_xgf_urls.yml
name: Find xgf.nu URLs (Max Speed & Full Verbose)

on:
  workflow_dispatch:
    inputs:
      count:
        description: 'チェックする URL 数'
        required: true
        default: 100000
        type: number
      concurrency:
        description: '同時リクエスト数'
        required: true
        default: 500
        type: number

permissions:
  contents: write

jobs:
  search:
    runs-on: ubuntu-latest
    env:
      COUNT: ${{ github.event.inputs.count }}
      CONCURRENCY: ${{ github.event.inputs.concurrency }}
      TIMEOUT: 5       # 秒
      RETRIES: 2       # 再試行回数

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install aiohttp asyncio tqdm

      - name: Create and run check script
        run: |
          cat > check_urls_async.py << 'EOF'
          import os, asyncio, random, string
          import aiohttp
          from tqdm import tqdm

          COUNT = int(os.getenv('COUNT', '100000'))
          CONCURRENCY = int(os.getenv('CONCURRENCY', '500'))
          TIMEOUT = float(os.getenv('TIMEOUT', '5'))
          RETRIES = int(os.getenv('RETRIES', '2'))
          USER_AGENT = "Mozilla/5.0 (compatible; XgfScanner/1.0)"

          sem = asyncio.Semaphore(CONCURRENCY)
          hits = []

          async def fetch(session, url):
              headers = {"User-Agent": USER_AGENT}
              for attempt in range(1, RETRIES + 2):
                  try:
                      async with session.get(url, headers=headers, timeout=TIMEOUT) as resp:
                          status = resp.status
                      print(f"[{url}] Attempt {attempt}: HTTP {status}")
                      # 200 or 403 をヒットとみなす
                      if status in (200, 403):
                          return True
                      return False
                  except Exception as e:
                      print(f"[{url}] Attempt {attempt} error: {e!r}")
                      if attempt <= RETRIES:
                          await asyncio.sleep(0.1)
                          continue
                      return False

          async def worker(_idx, session):
              slug = ''.join(random.choices(string.ascii_letters + string.digits, k=5))
              url = f"https://xgf.nu/{slug}"
              async with sem:
                  if await fetch(session, url):
                      hits.append(url)

          async def main():
              conn = aiohttp.TCPConnector(limit=CONCURRENCY)
              timeout = aiohttp.ClientTimeout(total=None)
              async with aiohttp.ClientSession(connector=conn, timeout=timeout) as session:
                  tasks = [worker(i, session) for i in range(COUNT)]
                  for coro in tqdm(asyncio.as_completed(tasks), total=COUNT):
                      await coro

              # 結果をファイルに書き出し
              with open('hits.txt', 'w') as f:
                  for u in hits:
                      f.write(u + "\n")
              print(f"===== Total hits: {len(hits)} =====")

          if __name__ == "__main__":
              asyncio.run(main())
          EOF

          # 古い結果を消去
          rm -f hits.txt

          # 実行
          python check_urls_async.py

      - name: Show log & hits.txt
        run: |
          echo "===== Log end. hits.txt contents ====="
          cat hits.txt || echo "(no hits found)"

      - name: Commit & Push hits.txt
        run: |
          if [ -s hits.txt ]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add hits.txt
            git commit -m "Update hits.txt (#${{ github.run_number }})"
            git push
          else
            echo "No hits to commit."
          fi
